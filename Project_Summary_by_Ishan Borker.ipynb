{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#                        Employee Performance Analysis\n",
    "#                                    INX Future Inc.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Candidate Name             : Ishan Pradip Borker\n",
    "    Candidate Email            : ishan123ppp@gmail.com\n",
    "    Assessment ID              : E10901-PR2-V18\n",
    "    REP Name                   : DataMites™ Solutions Pvt Ltd\n",
    "    Venue Name                 : Open Project\n",
    "    Exam Country               : India\n",
    "    Module                     : Certified Data Scientist - Project\n",
    "    Language                   : English\n",
    "    Exam Format                : Open Project- IABAC™ Project Submission\n",
    "    Submission Deadline Date   : 04-Apr-2020  \n",
    "    Submission Deadline Time   : 23:59 Hrs [IST]\n",
    "    Registered Trainer         : Ashok Kumar A \n",
    "    Project Assessment         : IABAC™"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Requirement\n",
    "INX Future Inc, (referred as INX ) , is one of the leading data analytics and automation solutions provider with over 15 years of global business presence. INX is consistently rated as top 20 best employers past 5 years. INX human resource policies are considered as employee friendly and widely perceived as best practices in the industry.\n",
    "Recent years, the employee performance indexes are not healthy and this is becoming a growing concern among the top management. There have been increased escalations on service delivery and client satisfaction levels came down by 8 percentage points.\n",
    "CEO, Mr. Brain, knows the issues but concerned to take any actions in penalizing non-performing employees as this would affect the employee morale of all the employees in general and may further reduce the performance. Also, the market perception best employer and thereby attracting best talents to join the company. Mr. Brain decided to initiate a data science project, which analyses the current employee data and find the core underlying causes of this performance issues. Mr. Brain, being a data scientist himself, expects\n",
    "the findings of this project will help him to take right course of actions. He also expects clear indicators of non performing employees, so that any penalization of non-performing employee, if required, may not significantly affect other employee morals.\n",
    "\n",
    "\n",
    "The following insights are expected from this project.\n",
    "1. Department wise performances\n",
    "2. Top 3 Important Factors effecting employee performance\n",
    "3. A trained model which can predict the employee performance based on factors as inputs. This will be used to hire employees.\n",
    "4. Recommendations to improve the employee performance based on insights from analysis.\n",
    "\n",
    "The entire project is done in Jupyter notebook by using Python language."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Analysis\n",
    "\n",
    "It is a classification problem. The data that is being provided consists of categorical fields and numerical fields.\n",
    "\n",
    "The categorical fields are **1. Gender, 2. EducationBackground, 3. MaritalStatus ,4. EmpDepartment, 5. EmpJobRole, 6. Business TravelFrequency ,7. Overtime , 8. Attrition**.\n",
    "These values are nominal, ordinal, ratio or interval.\n",
    "\n",
    "The numerical fields are **1. Age, 2. DistanceFromHome, 3. EmpEducationLevel, 4.EmpEnvironmentSatisfaction, 5.EmpHourlyRate, 6. EmpJobInvolvement, 7.EmpJobLevel, 8.EmpJobSatisfaction, 9. NumCompaniesWorked, 10. EmpLastSalaryHikePercent, 11.EmpRelationshipSatisfaction, 12.TotalWorkExperienceInYears, 13.TrainingTimesLastYear, 14.EmpWorkLifeBalance, 15. ExperienceYearsAtThisCompany, 16. ExperienceYearsInCurrentRole, 17. YearsSinceLastPromotion, 18.YearsWithCurrManager, 19. PerformanceRating**.\n",
    "\n",
    "These values are either discrete or continuous.\n",
    "\n",
    "The target variable '**PerformanceRating**' is ordinal.\n",
    "\n",
    "**Step 1**: Perform Exploratory Data Analysis(EDA).\n",
    "\n",
    "It includes\n",
    "\n",
    "1) Checking the datatypes of data.\n",
    "\n",
    "2) Finding the names of the columns present in the data, shape of the data, information of the data and describing the data.\n",
    "\n",
    "3) Checking for the null values if they are present in the data and removing them.\n",
    "\n",
    "**Step 2**: Perform Visualization(Graphical Representation) inorder to carry out detailed analysis.\n",
    "\n",
    "1) Here, department wise performance analysis is carried out. \n",
    "\n",
    "2) Also each and every factor related to employee performance is being analyzed.\n",
    "\n",
    "**Step 3**: Checking for the outliers and removing it.\n",
    "\n",
    "Outlier is a data point that differs significantly from other observations. \n",
    "\n",
    "An outlier is caused due to variability in the measurement or experimental error.\n",
    "\n",
    "It can cause serious problems in statistical analysis.\n",
    "\n",
    "We use boxplot to find out if any outliers are present in any of the fields of the data.\n",
    "\n",
    "Outliers were present in the following fields:\n",
    "<ol>\n",
    "    <li>TotalWorkExperienceInYears</li>\n",
    "    <li>ExperienceYearsAtThisCompany</li>\n",
    "    <li>YearsSinceLastPromotion</li>\n",
    "</ol>    \n",
    "\n",
    "After removing , we drop these fields and generated the corresponding new fields were generated as \n",
    "<ol>\n",
    "    <li>clean_TotalWorkExperienceInYears</li>\n",
    "    <li>clean_ExperienceYearsAtThisCompany</li>\n",
    "    <li>clean_YearsSinceLastPromotion</li> \n",
    "</ol>\n",
    "\n",
    "**Step 4**: Define X and y variables.\n",
    "\n",
    "Here X represents input variables and y represents output variable.\n",
    "\n",
    "**Step 5**: Using Train-Test split ,scaling, standard scaling.\n",
    "\n",
    "Train-Test split splits arrays or matrices into random train and test subsets.\n",
    "\n",
    "Scale standardizes a dataset along any axis.\n",
    "\n",
    "Standard Scaler standardizes features by removing the mean and scaling to unit variance.\n",
    "\n",
    "**Step 6**: Machine Learning Algorithm to predict the employee performance.\n",
    "\n",
    "Algorithms used are \n",
    "\n",
    "<ul>\n",
    "    <li>Random Forest Classifier</li>\n",
    "    <li>Gradient Boosting Classifier</li>\n",
    "    <li>XGBoost Classifier</li>\n",
    "    <li>Artificial Neural Networks</li>\n",
    "    <li>K- Nearest Neighbors</li>\n",
    "    <li>Logistic Regression</li>\n",
    "    <li>Support Vector machine</li>\n",
    "    <li>Decision Tree Classifier</li>\n",
    "</ul>\n",
    "Steps for designing the machine learning algorithms\n",
    "\n",
    "1. Import the required packages.\n",
    "2. Define and train the model.\n",
    "3. Predict the model.\n",
    "4. Display the confusion matrix and crosstab.\n",
    "5. Calculate the accuracy score, precision score, recall score and F1 score.\n",
    "6. Display the classification report.\n",
    "\n",
    "Other techniques used include:\n",
    "\n",
    "1. **Feature Engineering** in Random Forest Classifier \n",
    ">Steps: \n",
    ">1. Import the required package.\n",
    ">2. Sort the values as per the correlation with respect to Performance Rating.\n",
    ">3. Define X(input) and y(output) variables.\n",
    ">4. Use train-test split to divide test and train data.\n",
    ">5. Define the model.\n",
    ">6. Predict the model.\n",
    ">7. Display the confusion matrix and crosstab.\n",
    ">8. Calculate the accuracy score, precision score, recall score and F1 score.\n",
    ">9. Display the classification report.\n",
    "\n",
    "2. **Grid Search Cross Validation** (CV) in Random Forest Classifier \n",
    ">Steps: \n",
    ">1. Import the required package.\n",
    ">2. Use train-test split and standard scaler.\n",
    ">3. Define and train the model.\n",
    ">4. Find best_score_ and best_params_ values.\n",
    ">6. Predict the model.\n",
    ">7. Display the confusion matrix and crosstab.\n",
    ">8. Calculate the accuracy score, precision score, recall score and F1 score.\n",
    ">9. Display the classification report.\n",
    "\n",
    "3. **Randomized Search Cross Validation** (CV) in Random Forest Classifier \n",
    ">Steps: \n",
    ">1. Import the required package.\n",
    ">2. Use train-test split and standard scaler.\n",
    ">3. Define and train the model.\n",
    ">4. Find best_score_ and best_params_ values.\n",
    ">6. Predict the model.\n",
    ">7. Display the confusion matrix and crosstab.\n",
    ">8. Calculate the accuracy score, precision score, recall score and F1 score.\n",
    ">9. Display the classification report.\n",
    "\n",
    "4. **Synthetic Minority Over-sampling Technique** (SMOTE) in Random Forest Classifier \n",
    ">Steps: \n",
    ">1. Import the required package.\n",
    ">2. Use train-test split.\n",
    ">3. Define and train the model.\n",
    ">4. Predict the model.\n",
    ">5. Display the confusion matrix and crosstab.\n",
    ">6. Calculate the accuracy score, precision score, recall score and F1 score.\n",
    ">7. Display the classification report.\n",
    ">8.Displaying X_train and y_train data after performing Synthetic Minority Over-sampling Technique(SMOTE).\n",
    "\n",
    "A correlation matrix is being created to understand the relation of all the fields with respect to Performance Rating.  \n",
    "\n",
    "The factors which are positively correlated with Performance Rating are Environment Satisfaction, Last Salary Hike Percent and Work Life Balance.\n",
    "The factors which are negatively correlated with Performance Rating are Years Since Last Promotion, Experience Years In Current Role, Years With Current Manager and Experience Years At This Company.\n",
    "\n",
    "Also, a technique called Label Encoder is used to convert the categorical data into numerical data so that the predictive models can understand the data.\n",
    "The fields which are converted to numericals using Label Encoder are\n",
    "**1) EmpNumber, 2) Gender, 3) EducationBackground, 4) MaritalStatus ,5) EmpDepartment, 6) EmpJobRole, 7) BusinessTravelFrequency ,8) Overtime , 9) Attrition**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Summary\n",
    "\n",
    "In this project, we try to figure out which department has performed well, factors which affect employee performance and train a model using machine learning algorithm to predict the Performance Rating.\n",
    "\n",
    "We also analyze the data and give recommendation to improve the employee's performance.\n",
    "\n",
    "### 1. Department wise performances\n",
    "\n",
    "By using the field called Performance Rating and finding the mean of the values for all the departments, we can conclude that\n",
    "department which has the highest average performance rating is '**Development**' and the department which has the lowest \n",
    "performance rating is '**Finance**'.\n",
    "\n",
    "The following are the average Performance Ratings of each Department:\n",
    "\n",
    "Data Science      -->        3.050000\n",
    "\n",
    "Development       -->        3.085873\n",
    "\n",
    "Finance           -->        2.775510\n",
    "\n",
    "Human Resources   -->        2.925926\n",
    "\n",
    "Research & Development -->   2.921283\n",
    "\n",
    "Sales             -->        2.860590\n",
    "\n",
    "Also the analysis for Male/Female Performance Rating was done. \n",
    "                        \n",
    "We can conclude that the highest average performance rating for Males is in '**Data Science**' Department and lowest is in '**Finance**' Department.\n",
    "\n",
    "The highest average performance rating for Females is in '**Development**' Department and lowest is in '**Finance**' Department.\n",
    "\n",
    "Overall Average Performance Rating of Females is more compared to Males.\n",
    "\n",
    "Female -->   2.949474\n",
    "Male   -->   2.947586\n",
    "\n",
    "Also analysis of each department is carried out with respect to Performance Rating index 2,3 4.\n",
    "\n",
    "It was found that PerformanceRating 2 is highest in **Sales, Research and Development,Human Resources, Finance** departments.PerformanceRating 3 is highest in **Development and Data Science** department.\n",
    "PerformanceRating 4 is 2nd highest in **Development, Research and Development, Human Resources and Data Science** departments.\n",
    " \n",
    "### 2. The Top 3 Important Factors affecting the employee performance\n",
    "\n",
    "After the visualization and correlation matrix, it clearly indicates that the top 3 factors which affect the employee performance are\n",
    "\n",
    "1) Employee Environment Satisfaction --> 39.5561%\n",
    "\n",
    "2) Employee Last Salary Hike Percent --> 33.3722%\n",
    "\n",
    "3) Years Since Last Promotion --> 16.7629%\n",
    "\n",
    "\n",
    "\n",
    "### 3. A Trained Model which can predict the employee performance\n",
    "\n",
    "The trained model which are designed using machine learning algorithm to predict the employee performance are listed below along with their accuracy score and precision score as:\n",
    "\n",
    "<table style=\"width:100%\">\n",
    "<tr>\n",
    "    <th>Sr.No.</th>\n",
    "    <th>Machine Learning Algorithm</th>\n",
    "    <th>Accuracy Score</th>\n",
    "    <th>Precision Score</th>\n",
    "    <th>Recall Score</th>\n",
    "</tr>\n",
    "    \n",
    "<tr>\n",
    "    <td>1.</td>\n",
    "    <td>Random Forest Classifier</td>\n",
    "    <td>94.16%</td>\n",
    "    <td>94.03%</td>\n",
    "    <td>94.16%</td>\n",
    "</tr>  \n",
    "    \n",
    "\n",
    "<tr>\n",
    "    <td>2.</td>\n",
    "    <td>Gradient Boosting Forest Classifier</td>\n",
    "    <td>96.25%</td>\n",
    "    <td>96.22%</td>\n",
    "    <td>96.25%</td>\n",
    "</tr>  \n",
    "    \n",
    "\n",
    "<tr>\n",
    "    <td>3.</td>\n",
    "    <td>eXtreme Gradient Boosting(XGBoosting) Classifier</td>\n",
    "    <td>95.41%</td>\n",
    "    <td>95.39%</td>\n",
    "    <td>95.41%</td>\n",
    "</tr>  \n",
    "    \n",
    "<tr>\n",
    "    <td>4.</td>\n",
    "    <td> Artificial Neural Networks</td>\n",
    "    <td>80.41%</td>\n",
    "    <td>78.91%</td>\n",
    "    <td>80.41%</td>\n",
    "</tr>     \n",
    "    \n",
    "<tr>\n",
    "    <td>5.</td>\n",
    "    <td> K- Nearest Neighbors </td>\n",
    "    <td>75.41%</td>\n",
    "    <td>66.88%</td>\n",
    "    <td>75.41%</td>\n",
    "</tr> \n",
    "    \n",
    "    \n",
    "<tr>\n",
    "    <td>6.</td>\n",
    "    <td>Logistic Regression</td>\n",
    "    <td>83.33%</td>\n",
    "    <td>83.33%</td>\n",
    "    <td>83.33%</td>\n",
    "</tr> \n",
    "    \n",
    "\n",
    "<tr>\n",
    "    <td>7.</td>\n",
    "    <td>Support Vector Machine</td>\n",
    "    <td>80.83%</td>\n",
    "    <td>80.83%</td>\n",
    "    <td>80.83%</td>\n",
    "</tr> \n",
    "    \n",
    "<tr>\n",
    "    <td>8.</td>\n",
    "    <td>Decision Tree Classifier</td>\n",
    "    <td>92.08%</td>\n",
    "    <td>92.53%</td>\n",
    "    <td>92.08%</td>\n",
    "</tr>    \n",
    "   \n",
    "\n",
    "The Machine Learning Algorithm which has the highest accuracy, precision and recall is '**Gradient Boosting Classifier**'. \n",
    "'**K-Nearest Neighbors**' algorithm has the lowest accuracy, precision and recall.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Insights\n",
    "\n",
    "Here Visualization of each factor was carried out to check for the employee performance. The results were\n",
    "\n",
    "1) BusinessTravelFrequency : 'Non-Travel' employees performed better.\n",
    "\n",
    "2) DistanceFromHome : Employees staying 16km away from home performed better.\n",
    "\n",
    "3) EmpEducationLevel : Employees having education level 3 is the highest.\n",
    "\n",
    "4) EmpEnvironmentSatisfaction : Environment Satisfaction Level 3 performed better.\n",
    "\n",
    "5) EmpJobInvolvement : Employees Job Involvement level 2 performed better.\n",
    "\n",
    "6) EmpJobLevel : Employee Job Level 1 performed better.\n",
    "\n",
    "7) EmpJobSatisfaction : Employee Job Satisfaction level 4 performed better.\n",
    "\n",
    "8) OverTime : Employees working overtime performed better.\n",
    "\n",
    "9) EmpLastSalaryHikePercent : Employees who received 21% hike in the salary has better performance.\n",
    "\n",
    "10) NumCompaniesWorked : Employees who worked in 4 different companies performed better on the job.\n",
    "\n",
    "11) EmpRelationshipSatisfaction : Employee having Relationship Satisfaction level 3 has performed better.\n",
    "\n",
    "12) TrainingTimesLastYear : Employees who have been trained 3 times last year have performed better.\n",
    "\n",
    "13) EmpWorkLifeBalance : Employees having Worklife Balance level 4 has highest performance rating.\n",
    "\n",
    "14) ExperienceYearsAtThisCompany : Employees who have 23 and 34 years of experience in this company performed better.\n",
    "\n",
    "15) ExperienceYearsInCurrentRole : Employees having 12 years of experience in the current role performed better.\n",
    "\n",
    "16) YearsSinceLastPromotion : Employees who haven't been promoted since 13 years after their last promotion have performed better.\n",
    "\n",
    "17) YearsWithCurrManager : Employees who spent 17 years with the current manager has better performance rating.\n",
    "\n",
    "18) EmpHourlyRate : Employees working at the rate of 38 hours have performed better.\n",
    "\n",
    "19) Attrition : Employees who haven't resigned from many jobs have performed better.\n",
    "\n",
    "**Note**: Graphs for all these factors can be found from \"**INX-Future-Inc_Employee_Performance_Analysis_by_IshanBorker.ipnb**\" source code file.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li> Using Feature Engineering in Random Forest Classifier,</li>\n",
    "\n",
    "> Accuracy Score was 92.91% , Precision Score was 92.71% and Recall Score was 92.91%.\n",
    "\n",
    "<li> Using GridSearch Cross Validation in Random Forest Classifier, </li>\n",
    "\n",
    "> Accuracy Score was 80% ,Precision Score was 83.33% and Recall Score was 80%.\n",
    "\n",
    "<li> Using RandomizedSearch Cross Validation in Random Forest Classifier,</li> \n",
    "\n",
    "> Accuracy Score was 80% ,Precision Score was 83.33% and Recall Score was 80%.\n",
    "\n",
    "<li> Using Synthetic Minority Over-sampling Technique in Random Forest Classifier,</li>\n",
    "\n",
    "> Accuracy Score was 89.16% ,Precision Score was 90.27% and Recall Score was 89.16%.\n",
    "\n",
    "**Feature Engineering** technique results in highest accuracy score, precision score and recall score.\n",
    "**GridSearch Cross Validation** and **RandomizedSearch Cross Validation** techniques result in lowest accuracy score , precision score and recall score.\n",
    "\n",
    "**Gradient Boosting Classifier** results in highest accuracy, precision and recall.\n",
    "Also **Random Forest Classifier**, **eXtreme Gradient Boosting Classifier** and **Decision tree Classifier** results in more than 90% accuracy, precision and recall. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Recommendations to improve the employee performance\n",
    "\n",
    "<ul>\n",
    "    <li>I recommend that the company should focus on the three factors that affect employee performance i.e.Employee Environment Satisfaction, Last Salary Hike Percent and Years Since Last Promotion and improve on them.</li>\n",
    "    <li>It means that employee needs to be happy on the job.</li>\n",
    "    <li>The salary of the employees needs to be raised twice a year and those who perform better needs to be promoted every year. This will inturn boost the confidence of the employees.</li>\n",
    "    <li>The other factors like Experience Years In Current Role (14.76%) , Employee Work Life Balance (12.44%), Years With Current Manager(12.23%) also needs to be monitored carefully for better functioning of the organisation.</li>\n",
    "    <li>Males need to work hard inorder to be in par with Females with respect to Performance.They need to improve in Human Resources and Finance Departments.</li>\n",
    "    <li>Females need to work better in Sales and Finance departments.</li>\n",
    "    <li>Finance Department needs to closely monitor their employees as both males and females have not performed better.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Answers to the following questions\n",
    "\n",
    "### 1. The algorithm and training method(s) you used (Such as SVM, Neural Network etc.,)\n",
    "\n",
    "Ans) The algorithms used for this project are \n",
    "\n",
    "<ol>\n",
    "    <li>Random Forest Classifier</li>\n",
    "    <li>Gradient Boosting Classifier</li>\n",
    "    <li>XGBoost Classifier</li>\n",
    "    <li>Artificial Neural Networks</li>\n",
    "    <li>K- Nearest Neighbors</li>\n",
    "    <li>Logistic Regression</li>\n",
    "    <li>Support Vector machine</li>\n",
    "    <li>Decision Tree Classifier</li>\n",
    "</ol>\n",
    "\n",
    "\n",
    "### 2. The most important features selected for analysis and why? (Whether techniques such as PCA Factorization used)\n",
    "\n",
    "Ans) The most important features selected for analysis were 1. EmpDepartment , 2. Gender , 3. BusinessTravelFrequency, 4. DistanceFromHome, 5.EmpEducationLevel, 6. EmpEnvironmentSatisfaction, 7. EmpJobInvolvement, 8. EmpJobLevel, 9. EmpJobSatisfaction, 10. OverTime, 11. EmpLastSalaryHikePercent, 12. NumCompaniesWorked, 13. EmpRelationshipSatisfaction, 14. TrainingTimesLastYear, 15. EmpWorkLifeBalance, 16. ExperienceYearsAtThisCompany, 17. ExperienceYearsInCurrentRole, 18. YearsSinceLastPromotion, 19. YearsWithCurrManager, 20. EmpHourlyRate, 21. Attrition\n",
    "\n",
    "All these features were selected because they form the major part in employee appraisal as well as company's performance.\n",
    "\n",
    "The techniques used in the analysis were\n",
    "\n",
    "1.\tGrid Search Cross Validation (CV) in Random Forest Classifier : It is the process of performing hyper parameter tuning in order to determine the optimal values for a model. The performance of the entire model is based on the hyper parameter values.\n",
    "\n",
    "2.  Randomized Search Cross Validation(CV) in Random Forest Classifier :Random search is a technique where random combinations of the hyperparameters are used to find the best solution for the built model. The chances of finding the optimal parameters are  higher in random search because of the random search pattern where the model ends up being trained on the optimised parameters.\n",
    "\n",
    "3.\tSynthetic Minority Over-sampling Technique(SMOTE) in Random Forest Classifier : It is an oversampling method and creates the synthetic samples of minority class.It aims to balance class distribution by randomly increasing minority class examples by replicating them.\n",
    "\n",
    "4.\tLabel Encoder for Data Processing and Data Munging : To convert the categorical data into numerical data so that it is easier for predictive models to understand the data. \n",
    "\n",
    "\n",
    "\n",
    "### 3. Other techniques and tools used in the project.\n",
    "\n",
    "Ans) The other techniques used in this project are \n",
    "\n",
    "1. Scaling Technique : It standardizes the dataset on any axis.\n",
    "\n",
    "2. Standard Scaling Technique: It standardizes features by removing the mean and scaling to unit variance.\n",
    "\n",
    "3. Feature Engineering Technique : It uses the domain knowledge to extract features from the raw data. These features help to improve the performance of the machine learning algorithms. \n",
    "\n",
    "Tools \n",
    "Packages used in this project are **matplotlib, pyplot, seaborn, numpy, pandas, sklearn, collections, imblearn, xgboost**.\n",
    "\n",
    "\n",
    "\n",
    "### 4. Did you make any important feature transformations?\n",
    "\n",
    "Ans) Yes, outliers were present in some of the fields like \n",
    "\n",
    "\n",
    "<ol>\n",
    "    <li>TotalWorkExperienceInYears</li>\n",
    "    <li>ExperienceYearsAtThisCompany</li>\n",
    "    <li>YearsSinceLastPromotion</li>\n",
    "</ol>\n",
    "\n",
    "\n",
    "They were removed and new features were created (after transformation)  as follows:\n",
    "\n",
    "\n",
    "<ol>\n",
    "    <li>clean_TotalWorkExperienceInYears</li>\n",
    "    <li>clean_ExperienceYearsAtThisCompany</li>\n",
    "    <li>clean_YearsSinceLastPromotion</li>\n",
    "</ol>\n",
    "\n",
    "\n",
    "Then the features which were present before transformation were dropped from the dataframe. This technique in turn results in \n",
    "much better accuracy for all the algorithms that are used in this project.  \n",
    "\n",
    "\n",
    "\n",
    "### 5. Correlation or interactions among the features selected and how it is considered?\n",
    "\n",
    "Ans) Yes correlation was selected among the features using python code\n",
    "\n",
    "**corr = performance.corr()** where performance is the dataframe containing the data of employee performance prediction. \n",
    "\n",
    "This will help used to find the pairwise correlation of all columns in the dataframe. It generates the correlation matrix.\n",
    "\n",
    "Also we have to use heatmap to get the visual representation of correlation matrix which is supported by package called \n",
    "seaborn.\n",
    "\n",
    "\n",
    "\n",
    "### 6. Did you find any interesting relationships in the data that don't fit in the sections above?\n",
    "\n",
    "Ans) The fields like ExperienceYearsAtThisCompany, ExperienceYearsInCurrentRole, YearsSinceLastPromotion, YearsWithCurrManager are most positively correlated against each other compared all the other fields. \n",
    "It is depicted in yellow color rectangle as in Correlation heat map.\n",
    "\n",
    "\n",
    "### 7. What is most important technique you used in this project?\n",
    "\n",
    "Ans) The most important technique used in this project is Feature Engineering in Random Forest Classifier by sorting the values based on correlation with Performance Rating.\n",
    "The results were 1. Accuracy =   92.91% , 2. Precision score =  92.71% , 3. Recall score =  92.91%.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
